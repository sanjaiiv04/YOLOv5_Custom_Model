{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEDFYIGnNgLD",
    "outputId": "933a4ea2-1426-4ad0-c17d-ebbd08ccdecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 15967, done.\u001b[K\n",
      "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
      "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
      "remote: Total 15967 (delta 43), reused 51 (delta 24), pack-reused 15880\u001b[K\n",
      "Receiving objects: 100% (15967/15967), 14.64 MiB | 2.82 MiB/s, done.\n",
      "Resolving deltas: 100% (10942/10942), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHU8M5DfNwX3",
    "outputId": "47b7df75-d52f-4ecc-bca4-72b2ae1195e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vijayakumarmuthusamy/Desktop/yolo_custom/yolov5\n"
     ]
    }
   ],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f-P0jyiNy5I",
    "outputId": "3c3c9744-4318-4782-c014-483e99d058f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
      "  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.2)\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
      "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
      "  Downloading ultralytics-8.0.178-py3-none-any.whl (616 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.4/616.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 15)) (3.27.4.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 15)) (16.0.6)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n",
      "Successfully installed gitdb-4.0.10 gitpython-3.1.36 smmap-5.0.0 thop-0.1.1.post2209072238 ultralytics-8.0.178\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JBgoLwRN24s"
   },
   "outputs": [],
   "source": [
    "!mkdir vehicles_open_image\n",
    "%cd vehicles_open_image\n",
    "!curl -L \"https://public.roboflow.com/ds/2Tb6yXY8l8?key=Eg82WpxUEr\" > vehicles.zip\n",
    "!unzip vehicles.zip\n",
    "!rm vehicles.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GC-ZlYrzSmZ0"
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mLHSAV-SnFj"
   },
   "outputs": [],
   "source": [
    "config = {'path': '/content/yolov5/vehicles_open_image',\n",
    "         'train': '/content/yolov5/vehicles_open_image/train',\n",
    "         'val': '/content/yolov5/vehicles_open_image/valid',\n",
    "         'nc': 5,\n",
    "         'names': ['Ambulance', 'Bus', 'Car', 'Motorcycle', 'Truck']}\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as file:\n",
    "   yaml.dump(config, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJR4NsUISqH0"
   },
   "outputs": [],
   "source": [
    "SIZE = 640\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "MODEL = \"yolov5s\"\n",
    "WORKERS = 1\n",
    "PROJECT = \"vehicles_open_image_pyimagesearch\"\n",
    "RUN_NAME = f\"{MODEL}_size{SIZE}_epochs{EPOCHS}_batch{BATCH_SIZE}_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwYKpNFLTvmG",
    "outputId": "1fcff52a-6927-4a61-9a9a-5c7991a6465b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vijayakumarmuthusamy/Desktop/yolo_custom/yolov5\n"
     ]
    }
   ],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnSbQH5bTF8J",
    "outputId": "c41b2fd6-360a-4dff-8ae6-42e1b1e36cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/vehicles_open_image/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=1, project=vehicles_open_image_pyimagesearch, name=yolov5s_size640_epochs20_batch32_small, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-218-g9e97ac3 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir vehicles_open_image_pyimagesearch', view at http://localhost:6006/\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100% 755k/755k [00:00<00:00, 46.2MB/s]\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100% 14.1M/14.1M [00:00<00:00, 274MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7033114 parameters, 7033114 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/vehicles_open_image/train/labels... 878 images, 0 backgrounds, 0 corrupt: 100% 878/878 [00:00<00:00, 1796.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/vehicles_open_image/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/vehicles_open_image/valid/labels... 250 images, 0 backgrounds, 0 corrupt: 100% 250/250 [00:00<00:00, 785.97it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/vehicles_open_image/valid/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.82 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mvehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/19      6.82G    0.09554     0.0359    0.04443         56        640: 100% 28/28 [00:30<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:06<00:00,  1.51s/it]\n",
      "                   all        250        454      0.182      0.368      0.208     0.0936\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/19      8.44G    0.06389     0.0288    0.03065         47        640: 100% 28/28 [00:25<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "                   all        250        454      0.397      0.461      0.389      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/19      8.44G    0.06104     0.0257    0.02443         62        640: 100% 28/28 [00:25<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.07it/s]\n",
      "                   all        250        454      0.342      0.498      0.347      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/19      8.44G     0.0586    0.02433    0.01916         51        640: 100% 28/28 [00:25<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.09it/s]\n",
      "                   all        250        454      0.277      0.426      0.276      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/19      8.44G    0.05399    0.02353    0.01767         38        640: 100% 28/28 [00:25<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.22s/it]\n",
      "                   all        250        454       0.36      0.491      0.385       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/19      8.44G    0.04752    0.02302    0.01542         43        640: 100% 28/28 [00:24<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.07s/it]\n",
      "                   all        250        454      0.388      0.488      0.401      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/19      8.44G    0.04556    0.02226    0.01562         43        640: 100% 28/28 [00:25<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.07it/s]\n",
      "                   all        250        454      0.414      0.548      0.434      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/19      8.44G     0.0429    0.02225    0.01362         59        640: 100% 28/28 [00:25<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.09it/s]\n",
      "                   all        250        454      0.421       0.54       0.45      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/19      8.44G    0.04215     0.0218    0.01299         56        640: 100% 28/28 [00:25<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.21s/it]\n",
      "                   all        250        454      0.501      0.559      0.498      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/19      8.44G    0.03971    0.02139    0.01111         54        640: 100% 28/28 [00:25<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.07it/s]\n",
      "                   all        250        454      0.486      0.451       0.46      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/19      8.44G    0.03898    0.02045    0.01016         49        640: 100% 28/28 [00:25<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.12it/s]\n",
      "                   all        250        454      0.628      0.494      0.582      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/19      8.44G    0.03746    0.02081   0.009694         59        640: 100% 28/28 [00:25<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.08it/s]\n",
      "                   all        250        454      0.646      0.517      0.591       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/19      8.44G    0.03655    0.01975   0.008239         44        640: 100% 28/28 [00:24<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.25s/it]\n",
      "                   all        250        454      0.541      0.571      0.524      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/19      8.44G    0.03427    0.01914   0.008527         59        640: 100% 28/28 [00:24<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "                   all        250        454      0.596       0.56       0.55      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/19      8.44G    0.03389    0.01963   0.006935         35        640: 100% 28/28 [00:25<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.07it/s]\n",
      "                   all        250        454      0.582      0.522      0.542      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/19      8.44G    0.03174     0.0186   0.006611         61        640: 100% 28/28 [00:25<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.14it/s]\n",
      "                   all        250        454      0.729      0.498      0.604      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/19      8.44G     0.0314    0.01897   0.006478         58        640: 100% 28/28 [00:25<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.21s/it]\n",
      "                   all        250        454      0.672      0.544      0.593      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/19      8.44G    0.03059    0.01771   0.005799         46        640: 100% 28/28 [00:24<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.06s/it]\n",
      "                   all        250        454      0.721      0.555      0.614      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/19      8.44G    0.02955     0.0169    0.00504         42        640: 100% 28/28 [00:25<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.14it/s]\n",
      "                   all        250        454       0.66      0.632      0.642      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/19      8.44G    0.02787    0.01708    0.00512         39        640: 100% 28/28 [00:24<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.09it/s]\n",
      "                   all        250        454      0.659        0.6      0.631      0.454\n",
      "\n",
      "20 epochs completed in 0.168 hours.\n",
      "Optimizer stripped from vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/weights/last.pt, 14.5MB\n",
      "Optimizer stripped from vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/weights/best.pt, 14.5MB\n",
      "\n",
      "Validating vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:07<00:00,  1.93s/it]\n",
      "                   all        250        454      0.661      0.632       0.64      0.454\n",
      "             Ambulance        250         64      0.678      0.875      0.866      0.699\n",
      "                   Bus        250         46       0.62      0.783      0.754      0.547\n",
      "                   Car        250        238      0.649      0.454      0.483      0.324\n",
      "            Motorcycle        250         46      0.599      0.715       0.65      0.402\n",
      "                 Truck        250         60      0.755      0.333      0.448      0.296\n",
      "Results saved to \u001b[1mvehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img {SIZE}\\\n",
    "               --batch {BATCH_SIZE}\\\n",
    "               --epochs {EPOCHS}\\\n",
    "               --data /content/yolov5/vehicles_open_image/data.yaml\\\n",
    "               --weights {MODEL}.pt\\\n",
    "               --workers {WORKERS}\\\n",
    "               --project {PROJECT}\\\n",
    "               --name {RUN_NAME}\\\n",
    "               --exist-ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3V3wuODbTGwz",
    "outputId": "5094c71d-2363-4708-fbdd-00204b06ab4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/ (stored 0%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/ (stored 0%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/val_batch1_pred.jpg (deflated 7%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/train_batch0.jpg (deflated 2%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/val_batch0_pred.jpg (deflated 7%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/results.png (deflated 7%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/train_batch2.jpg (deflated 1%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/R_curve.png (deflated 8%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/PR_curve.png (deflated 11%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/P_curve.png (deflated 7%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/confusion_matrix.png (deflated 22%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/val_batch2_pred.jpg (deflated 8%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/F1_curve.png (deflated 8%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/val_batch2_labels.jpg (deflated 8%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/opt.yaml (deflated 51%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/results.csv (deflated 82%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/val_batch1_labels.jpg (deflated 7%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/weights/ (stored 0%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/weights/best.pt (deflated 9%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/weights/last.pt (deflated 9%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/labels.jpg (deflated 25%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/val_batch0_labels.jpg (deflated 7%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/hyp.yaml (deflated 45%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/events.out.tfevents.1694680474.9d42a2983f74.800.0 (deflated 26%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/labels_correlogram.jpg (deflated 39%)\n",
      "  adding: content/yolov5/vehicles_open_image_pyimagesearch/yolov5s_size640_epochs20_batch32_small/train_batch1.jpg (deflated 1%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/yolov5/vehicles_open_image_pyimagesearch.zip /content/yolov5/vehicles_open_image_pyimagesearch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "6IcXhMXZk3BB",
    "outputId": "b7ca2cf4-fe44-4851-b82b-c3432a7a7fca"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_bf7a1022-fce4-4b49-84c2-8040a5520656\", \"vehicles_open_image_pyimagesearch.zip\", 34313548)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('vehicles_open_image_pyimagesearch.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYb5-BDZ7LXe",
    "outputId": "9012c4d7-0cc5-4b06-8a22-ad816d96bba0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkEaFBkT7al3",
    "outputId": "7c22f407-70b8-4d24-afad-827ce30982a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=0, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-218-g9e97ac3 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
      "\n",
      "[ WARN:0@2.690] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@2.691] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/yolov5/detect.py\", line 285, in <module>\n",
      "    main(opt)\n",
      "  File \"/content/yolov5/detect.py\", line 280, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/content/yolov5/detect.py\", line 109, in run\n",
      "    dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
      "  File \"/content/yolov5/utils/dataloaders.py\", line 367, in __init__\n",
      "    assert cap.isOpened(), f'{st}Failed to open {s}'\n",
      "AssertionError: 1/1: 0... Failed to open 0\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights yolov5s.pt --source 0"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolo_model",
   "language": "python",
   "name": "yolo_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
